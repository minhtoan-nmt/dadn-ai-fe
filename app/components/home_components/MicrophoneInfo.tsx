import { useEffect, useState, useRef } from "react";
import { GrMicrophone } from "react-icons/gr";

export default function MicrophoneInfo() {
    const [isRecording, setIsRecording] = useState(false);
    const [transcript, setTranscript] = useState("");

    const transcriptRef = useRef("");
    const recognitionRef = useRef<any>(null);

    // Ref n√†y d√πng ƒë·ªÉ ch·∫∑n vi·ªác g·ª≠i API khi kh√¥ng ph·∫£i do ng∆∞·ªùi d√πng ch·ªß ƒë·ªông t·∫Øt
    // (Tu·ª≥ ch·ªçn, nh∆∞ng t·ªët cho UX)
    const isManualStopRef = useRef(false);

    useEffect(() => {
        const SpeechRecognition =
            (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;

        if (!SpeechRecognition) {
            alert("Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ SpeechRecognition API");
            return;
        }

        const recognition = new SpeechRecognition();
        recognition.lang = "vi-VN";
        recognition.continuous = true;
        recognition.interimResults = false;

        recognition.onresult = (event: any) => {
            let chunk = "";
            for (let i = event.resultIndex; i < event.results.length; i++) {
                if (event.results[i].isFinal) {
                    chunk += event.results[i][0].transcript + " ";
                }
            }

            if (chunk.trim() !== "") {
                console.log("ü¶ª V·ª´a nghe ƒë∆∞·ª£c:", chunk);
                setTranscript((prev) => {
                    const newText = prev + chunk;
                    transcriptRef.current = newText; 
                    return newText;
                });
            }
        };

        // --- QUAN TR·ªåNG: X·ª≠ l√Ω g·ª≠i API t·∫°i ƒë√¢y ---
        // S·ª± ki·ªán onend ch·∫°y khi mic ƒë√£ t·∫Øt h·∫≥n v√† d·ªØ li·ªáu ƒë√£ ch·ªët xong
        recognition.onend = async () => {
            setIsRecording(false); // ƒê·∫£m b·∫£o icon t·∫Øt
            console.log("üõë Microphone ƒë√£ t·∫Øt ho√†n to√†n (onend triggered).");

            const finalContent = transcriptRef.current.trim();
            
            // Ch·ªâ g·ª≠i n·∫øu c√≥ n·ªôi dung v√† (tu·ª≥ ch·ªçn) do ng∆∞·ªùi d√πng b·∫•m t·∫Øt
            if (finalContent && isManualStopRef.current) {
                console.log("üöÄ ƒêang g·ª≠i n·ªôi dung:", finalContent);
                try {
                    const res = await fetch(`http://localhost:3000/api/voicecontrol`, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        credentials: "include",
                        body: JSON.stringify({ 
                            text: finalContent 
                        })
                    });
                    
                    if (res.ok) console.log("‚úÖ G·ª≠i API th√†nh c√¥ng!");
                } catch (error) {
                    console.error('API Error:', error);
                }
            } else {
                console.log("‚ö†Ô∏è Kh√¥ng g·ª≠i API (Do kh√¥ng c√≥ n·ªôi dung ho·∫∑c mic t·ª± t·∫Øt)");
            }
            
            // Reset c·ªù manual stop
            isManualStopRef.current = false;
        };

        recognition.onerror = (e: any) => {
            console.error("Speech error:", e);
            setIsRecording(false);
        };
        
        recognitionRef.current = recognition;
    }, []);

    const handleToggleRecord = () => {
        if (!recognitionRef.current) return;

        if (!isRecording) {
            // --- B·∫ÆT ƒê·∫¶U ---
            setTranscript("");
            transcriptRef.current = "";
            recognitionRef.current.start();
            setIsRecording(true);
            console.log("üî¥ B·∫ÆT ƒê·∫¶U thu √¢m...");
        } else {
            // --- K·∫æT TH√öC ---
            // ƒê√°nh d·∫•u l√† ng∆∞·ªùi d√πng ch·ªß ƒë·ªông t·∫Øt
            isManualStopRef.current = true;
            recognitionRef.current.stop();
            // KH√îNG g·ª≠i API ·ªü ƒë√¢y n·ªØa. ƒê·ªÉ onend lo.
            console.log("‚è≥ ƒê√£ b·∫•m t·∫Øt, ƒë·ª£i x·ª≠ l√Ω...");
        }
    };

    return (
        <div className="w-xs h-fit bg-white rounded-xl p-3">
            <h1 className="text-center font-semibold text-2xl">Microphone</h1>

            <div className="flex justify-center">
                <GrMicrophone
                    size={175}
                    className={
                        "p-5 cursor-pointer rounded-full m-5 transition " +
                        (isRecording ? "text-red-500 bg-red-100" : "hover:bg-gray-200")
                    }
                    onClick={handleToggleRecord}
                />
            </div>

            {transcript && (
                <div className="p-3 bg-gray-100 rounded-lg text-sm max-h-40 overflow-y-auto border border-gray-300">
                    <b className="text-gray-600">K·∫øt qu·∫£:</b>
                    <p className="mt-1 text-gray-800 font-medium">{transcript}</p>
                </div>
            )}
        </div>
    );
}