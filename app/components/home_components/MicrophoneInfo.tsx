import { useEffect, useState, useRef } from "react";
import { GrMicrophone } from "react-icons/gr";

export default function MicrophoneInfo() {
    const [isRecording, setIsRecording] = useState(false);
    const [transcript, setTranscript] = useState("");
    const [apiResult, setApiResult] = useState<any>(null); 

    const transcriptRef = useRef(""); 
    const recognitionRef = useRef<any>(null);

    useEffect(() => {
        const SpeechRecognition =
            (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;

        if (!SpeechRecognition) {
            alert("Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ SpeechRecognition API");
            return;
        }

        const recognition = new SpeechRecognition();
        recognition.lang = "vi-VN";            
        recognition.continuous = true;          
        recognition.interimResults = false;     

        recognition.onresult = (event: any) => {
            let chunk = "";
            for (let i = event.resultIndex; i < event.results.length; i++) {
                if (event.results[i].isFinal) {
                    chunk += event.results[i][0].transcript + " ";
                }
            }

            if (chunk.trim() !== "") {
                console.log("ü¶ª V·ª´a nghe ƒë∆∞·ª£c:", chunk);
                setTranscript((prev) => {
                    const newText = prev + chunk;
                    transcriptRef.current = newText;
                    return newText;
                });
            }
        };

        recognition.onerror = (e: any) => console.error("Speech error:", e);
        recognitionRef.current = recognition;
    }, []);

const handleToggleRecord = async () => {
        if (!recognitionRef.current) return;

        if (!isRecording) {
            // ==========================================
            // TR∆Ø·ªúNG H·ª¢P 1: MU·ªêN B·∫¨T MIC
            // ==========================================
            try {
                // Th·ª≠ kh·ªüi ƒë·ªông Mic
                recognitionRef.current.start();
                
                // N·∫øu start th√†nh c√¥ng th√¨ m·ªõi update state v√† reset bi·∫øn
                console.log("üî¥ B·∫ÆT ƒê·∫¶U thu √¢m...");
                setIsRecording(true); 
                setTranscript(""); 
                setApiResult(null); 
                transcriptRef.current = "";
                
            } catch (error) {
                console.warn("‚ö†Ô∏è Mic ƒëang b·∫≠n ho·∫∑c ƒë√£ ƒë∆∞·ª£c b·∫≠t t·ª´ tr∆∞·ªõc:", error);
                // N·∫øu l·ªói "already started", ta c·ª© coi nh∆∞ n√≥ ƒëang b·∫≠t v√† c·∫≠p nh·∫≠t UI th√†nh ƒëang b·∫≠t
                setIsRecording(true);
            }
        } else {
            // ==========================================
            // TR∆Ø·ªúNG H·ª¢P 2: MU·ªêN T·∫ÆT MIC
            // ==========================================
            recognitionRef.current.stop();
            console.log("üõë ƒê√É T·∫ÆT MIC. ƒêang ch·ªù x·ª≠ l√Ω text cu·ªëi c√πng...");
            setIsRecording(false); // C·∫≠p nh·∫≠t UI t·∫Øt ngay l·∫≠p t·ª©c

            // Ch·ªù 1s ƒë·ªÉ tr√¨nh duy·ªát x·ª≠ l√Ω xong chunk cu·ªëi c√πng
            setTimeout(async () => {
                const finalContent = transcriptRef.current;
                console.log("üìù N·ªôi dung sau khi ch·ªù:", `"${finalContent}"`);

                if (!finalContent || finalContent.trim() === "") {
                    console.warn("‚ö†Ô∏è Kh√¥ng nghe th·∫•y g√¨, h·ªßy g·ª≠i API.");
                    return;
                }

                try {
                    console.log("üöÄ ƒêang g·ª≠i text t·ªõi AI API:", finalContent);
                    
                    const aiRes = await fetch("http://localhost:3000/api/ai/command", {
                        method: "POST",
                        credentials: "include",
                        headers: {
                            "Content-Type": "application/json",
                        },
                        body: JSON.stringify({ text: finalContent }),
                    });

                    if (aiRes.ok) {
                        const data = await aiRes.json();
                        console.log("‚úÖ API AI tr·∫£ v·ªÅ:", data);
                        setApiResult(data);

                        // B·∫ÆN S·ª∞ KI·ªÜN ƒê·ªÇ C·∫¨P NH·∫¨T UI
                        if (data.label) {
                            console.log("üì¢ Dispatching event:", data.label);
                            const event = new CustomEvent("ai-command-completed", { 
                                detail: { label: data.label } 
                            });
                            window.dispatchEvent(event);
                        }
                    } else {
                        console.error("‚ùå API l·ªói:", aiRes.status);
                        setApiResult({ error: `L·ªói API: ${aiRes.status}` });
                    }
                } catch (error) {
                    console.error("‚ùå L·ªói k·∫øt n·ªëi:", error);
                    setApiResult({ error: "Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn server" });
                }
            }, 1000); 
        }

        // G·ªçi API Toggle microphone (gi·ªØ nguy√™n logic backend c·ªßa b·∫°n)
        try {
            await fetch(`http://localhost:3000/api/device/statusToggle/microphone`, {
                method: 'POST',
                credentials: "include"
            });
        } catch (error) {}
    };
    
    return (
        <div className="w-xs h-fit bg-white rounded-xl p-3 flex flex-col gap-3">
            <h1 className="text-center font-semibold text-2xl">Microphone</h1>

            <div className="flex justify-center">
                <GrMicrophone
                    size={175}
                    className={
                        "p-5 cursor-pointer rounded-full transition " +
                        (isRecording ? "text-red-500 bg-red-100" : "hover:bg-gray-200")
                    }
                    onClick={handleToggleRecord}
                />
            </div>

            {transcript && (
                <div className="p-3 bg-gray-100 rounded-lg text-sm border border-gray-300">
                    <b className="text-gray-600">B·∫°n ƒë√£ n√≥i:</b>
                    <p className="mt-1 text-gray-800">{transcript}</p>
                </div>
            )}

            {apiResult && (
                <div className="p-3 bg-blue-50 rounded-lg text-sm border border-blue-200 overflow-x-auto">
                    <b className="text-blue-700">Ph·∫£n h·ªìi t·ª´ AI:</b>
                    <pre className="mt-2 text-xs text-blue-900 font-mono whitespace-pre-wrap">
                        {JSON.stringify(apiResult, null, 2)}
                    </pre>
                </div>
            )}
        </div>
    );
}